# Agentic RAG Pipeline

An agentic AI application built using **LangGraph**, **LangChain**, **Qdrant**, and **LangSmith**, demonstrating intelligent tool routing between real-time weather data and Retrieval-Augmented Generation (RAG) over documents, with a simple **Streamlit chat UI**.

This project is designed to showcase **clean architecture**, **agentic decision-making**, and **production-ready GenAI engineering practices**.

---

## ğŸš€ Features

- **Agentic workflow with LangGraph**
  - LLM-based router decides between tools at runtime
- **Real-time Weather Tool**
  - Fetches live weather data using OpenWeatherMap
- **RAG over PDF documents**
  - PDF ingestion, chunking, embedding, and retrieval
  - Vector storage using **Qdrant**
- **Local LLM & Embeddings**
  - Powered by **Ollama (Llama 3 + nomic-embed-text)**
- **LangSmith Tracing & Evaluation**
  - Full visibility into agent decisions and LLM calls
- **Streamlit Chat UI**
  - Interactive interface for demonstrating the agent

---

## ğŸ›  Tech Stack

- **Python 3.13**
- **LangChain** â€“ LLM orchestration
- **LangGraph** â€“ Agentic workflows
- **Qdrant** â€“ Vector database
- **Ollama** â€“ Local LLM & embeddings
- **LangSmith** â€“ Tracing & evaluation
- **Streamlit** â€“ UI
- **Pytest** â€“ Testing

---

## ğŸ“‚ Project Structure

agentic-rag-pipeline/
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ graph/
â”‚ â”œâ”€â”€ graph.py # LangGraph wiring
â”‚ â”œâ”€â”€ router.py # LLM-based router
â”‚ â”œâ”€â”€ nodes.py # Weather node
â”‚ â””â”€â”€ state.py # Shared graph state
â”œâ”€â”€ rag/
â”‚ â”œâ”€â”€ loader.py # PDF loading & chunking
â”‚ â”œâ”€â”€ embeddings.py # Qdrant vector store
â”‚ â””â”€â”€ retriever.py # Retriever logic
â”œâ”€â”€ tools/
â”‚ â””â”€â”€ weather.py # Weather tool
â”œâ”€â”€ llm/
â”‚ â””â”€â”€ provider.py # Ollama LLM setup
â”œâ”€â”€ data/
â”‚ â””â”€â”€ world_cities.pdf # Sample document for RAG
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ test_graph.py # Graph sanity check
â”‚ â””â”€â”€ test_rag.py # RAG smoke test
â”œâ”€â”€ tests/ # Unit tests
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/agentic-rag-pipeline.git
cd agentic-rag-pipeline

### 2ï¸âƒ£ Create & Activate Virtual Environment

python3.13 -m venv venv
source venv/bin/activate

### 3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

### 4ï¸âƒ£ Install & Run Ollama

Install Ollama: https://ollama.com
ollama pull llama3
ollama pull nomic-embed-text

### 5ï¸âƒ£ Set Environment Variables

#### OpenWeather API
export OPENWEATHER_API_KEY="your_openweather_api_key"

#### Langsmith
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="your_langsmith_api_key"
export LANGCHAIN_PROJECT="agentic-rag-pipeline"

### â–¶ï¸ Running the Application
streamlit run app.py

ğŸ“Œ Design Decisions

- LLM-based routing instead of keyword matching for robustness

- Dependency injection for LLMs to enable easy provider swaps

- Qdrant vector store with pinned client version for stability

- Local LLMs for reproducibility and zero API cost

- Explicit state management via LangGraph